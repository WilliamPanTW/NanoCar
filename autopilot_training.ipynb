{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#设置一个名为CUDA_DEVICE_ORDER的环境变量，并将其值设置为\"PCI_BUS_ID\"\n",
    "#指定了CUDA设备的顺序按照PCI总线ID进行排序\n",
    "# Set the CUDA device order to PCI_BUS_ID\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "#指定了可见的CUDA设备的索引，索引为1，第二个索引从0开始 Set the CUDA visible devices to GPU with index 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#提供常用的数据集，模型和图像转换功能\n",
    "import torchvision\n",
    "#Python Imaging Library，用于图像处理和操作                              \n",
    "import PIL\n",
    "#用于在循环中显示进度条的库                                    \n",
    "from tqdm import tqdm\n",
    "#用于计算均方误差的函数                           \n",
    "from sklearn.metrics import mean_squared_error\n",
    "# 用于在Jupyter Notebook中显示内容\n",
    "from IPython.display import display\n",
    "#用于绘制图表和可视化数据的库\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#用于进行数值计算和数组操作的库\n",
    "import numpy as np\n",
    "\n",
    "#包含用于加载和处理自动驾驶数据集的代码\n",
    "from autopilot_dataset import AutopilotDataset\n",
    "# 包含自动驾驶模型的定义和训练代码\n",
    "from autopilot_model import AutopilotModel\n",
    "# 包含用于预处理图像和其他实用函数的代码。\n",
    "from autopilot_utils import preprocess_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置训练的批次大小,表示每次训练模型时使用的样本数量 Number of samples per batch during training\n",
    "BATCH_SIZE = 128\n",
    "# 设置最大训练轮数,表示模型将进行多少次完整的训练迭代 Maximum number of training epochs\n",
    "MAX_EPOCHS = 50\n",
    "# 设置早停的耐心值,表示如果在连续多少个训练轮后模型的性能没有改善，训练过程将被提前终止 \n",
    "# Number of epochs to wait before early stopping if the validation loss doesn't improve\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "\n",
    "# 设置初始学习率,表示模型在训练开始时使用的学习率 Initial learning rate for the optimizer\n",
    "INITIAL_LR = 0.0005\n",
    "# 设置学习率减小的耐心值, 学习率调整耐心值，表示如果在连续多少个训练轮后模型的性能没有改善，学习率将被降低 \n",
    "# Number of epochs to wait before reducing the learning rate\n",
    "LR_REDUCER_PATIENCE = 2\n",
    "# 设置学习率减小的因子,表示在学习率调整时将当前学习率乘以的比例   Factor by which to reduce the learning rate\n",
    "LR_REDUCER_FACTOR = 0.9\n",
    "\n",
    "# 设置可接受的测试损失阈值,表示当模型在测试集上的损失低于该值时被认为是令人满意的 Maximum acceptable testing loss for evaluating the model\n",
    "ACCEPTABLE_TESTING_LOSS = 0.1\n",
    "\n",
    "# 设置输入图像的帧大小 Size of the input frames (assumed to be square)\n",
    "FRAME_SIZE = 224\n",
    "\n",
    "# 设置保存训练好的模型的目录路径 Directory path for storing model files TODO: 不知道要不要修改路径\n",
    "MODELS_DIR = \"/home/greg/models/jetson/\"\n",
    "# 设置数据集的目录路径 Directory path for storing dataset files\n",
    "DATASETS_DIR = \"/home/greg/datasets/jetson/\"\n",
    "\n",
    "# 设置模型的版本或标识符  Version identifier for the model\n",
    "VERSION = \"2_16\"\n",
    " \n",
    "# 设置保存训练好的模型的文件路径 File path for saving/loading the model\n",
    "MODEL_PATH = MODELS_DIR + VERSION + \"_resnet18\" + \".pth\"\n",
    "# 设置训练数据集的目录路径 Directory path for the training dataset\n",
    "TRAINING_DATASET = DATASETS_DIR + \"training/\"\n",
    "# 设置验证数据集的目录路径 Directory path for the validation dataset\n",
    "VALIDATION_DATASET = DATASETS_DIR + \"validation/\"\n",
    "# 设置测试数据集的目录路径 Directory path for the testing dataset\n",
    "TESTING_DATASET = DATASETS_DIR + \"testing/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建训练数据集对象，并进行数据增强和内存保留设置, 它设置帧的大小, 应用了随机水平翻转、随机噪声、随机模糊和随机颜色调整等数据增强操作。\n",
    "# 用keep_images_in_ram参数指定将图像保存在内存中\n",
    "# Initialize the AutopilotModel with pre-trained weights\n",
    "training_dataset = AutopilotDataset(TRAINING_DATASET,\n",
    "                                    FRAME_SIZE,\n",
    "                                    random_horizontal_flip=True,\n",
    "                                    random_noise=True,\n",
    "                                    random_blur=True,\n",
    "                                    random_color_jitter=True,\n",
    "                                    keep_images_in_ram=True)\n",
    "# 创建训练数据集的数据加载器，指定批次大小和打乱顺序 \n",
    "training_loader = torch.utils.data.DataLoader(training_dataset,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True)\n",
    "\n",
    "# 创建验证数据集对象，不进行数据增强，并设置内存保留\n",
    "validation_dataset = AutopilotDataset(VALIDATION_DATASET,\n",
    "                                      FRAME_SIZE,\n",
    "                                      random_horizontal_flip=False,\n",
    "                                      random_noise=False,\n",
    "                                      random_blur=False,\n",
    "                                      random_color_jitter=False,\n",
    "                                      keep_images_in_ram=True)\n",
    "\n",
    "# 创建验证数据集的数据加载器，指定批次大小和打乱顺序\n",
    "#将validation_dataset作为数据源，设置批处理大小为BATCH_SIZE，并打开数据集的随机打乱顺序功能\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                shuffle=True)\n",
    "\n",
    "# 创建测试数据集对象，不进行数据增强，并设置内存保留\n",
    "testing_dataset = AutopilotDataset(TESTING_DATASET,\n",
    "                                   FRAME_SIZE,\n",
    "                                   random_horizontal_flip=False,\n",
    "                                   random_noise=False,\n",
    "                                   random_blur=False,\n",
    "                                   random_color_jitter=False,\n",
    "                                   keep_images_in_ram=True)\n",
    "# 创建测试数据集的数据加载器，指定批次大小为1，不打乱顺序\n",
    "testing_loader = torch.utils.data.DataLoader(testing_dataset,\n",
    "                                                batch_size=1,\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 创建自动驾驶模型对象，并加载预训练权重 Initialize the AutopilotModel with pre-trained weights\n",
    "model = AutopilotModel(pretrained=True)\n",
    "# 创建优化器对象，使用Adam优化器，并指定学习率为初始学习率\n",
    "# Initialize Adam optimizer with model parameters, Adam optimizer is used to update the model's parameters during training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=INITIAL_LR)\n",
    "# 创建学习率调度器对象，当验证损失不再改善时，减小学习率 \n",
    "# ReduceLROnPlateau scheduler adjusts the learning rate based on the validation loss. It reduces the learning rate when the validation loss plateaus.\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       'min',\n",
    "                                                       patience=LR_REDUCER_PATIENCE,\n",
    "                                                       factor=LR_REDUCER_FACTOR,\n",
    "                                                       verbose=True)\n",
    "# 创建损失函数对象，使用均方(MES)误差损失函数\n",
    "# Initialize the mean squared error (MSE) loss function. MSE loss is commonly used for regression problems, \n",
    "# such as predicting steering and throttle values. It computes the mean squared difference between the predicted and target values.\n",
    "loss_function = torch.nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 创建空列表以保存训练和验证损失, 初始化了用于记录训练和验证损失 List to store training losses for each epoch and List to store validation losses for each epoch\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# 初始化连续没有改善的轮数 Initializes the number of consecutive rounds without improvement \n",
    "# # Counter for tracking the number of epochs without improvement in validation loss\n",
    "epochs_without_improvement = 0 \n",
    "\n",
    "# 定义绘制损失函数曲线的函数,绘制训练损失和验证损失的图形 Function to plot the training and validation losses\n",
    "def plot_losses():\n",
    "    # 创建图形和轴对象\n",
    "    fig, ax = plt.subplots()\n",
    "    # 绘制训练损失曲线\n",
    "    ax.plot([x for x in range(len(training_losses))], training_losses, label='training_loss')\n",
    "    # 绘制验证损失曲线\n",
    "    ax.plot([x for x in range(len(validation_losses))], validation_losses, label='validation_loss')\n",
    "    # 设置横轴、纵轴和标题标签\n",
    "    ax.set(xlabel='epochs', ylabel='loss', title='Training Progress')\n",
    "    # 显示网格\n",
    "    ax.grid()\n",
    "    # 显示图例\n",
    "    plt.legend()\n",
    "    # 显示图形\n",
    "    plt.show()\n",
    "\n",
    "# 定义运行每个轮次的函数     Define the function that runs each round\n",
    "def run_epoch(tepoch, name, training):\n",
    "    epoch_loss = 0.0\n",
    "    iterations = 0\n",
    "    \n",
    "    for _, images, annotations in tepoch:\n",
    "        # 更新进度条描述 Updated the progress bar description\n",
    "        tepoch.set_description(f\"{name} Epoch {epoch}\")\n",
    "        \n",
    "        # 将图像和注释数据移至GPU   # Move images and annotation data to the GPU\n",
    "        images = images.cuda()\n",
    "        annotations = annotations.cuda()\n",
    "        \n",
    "        if training:\\\n",
    "            # 清零优化器梯度  Clear the optimizer gradient\n",
    "            optimizer.zero_grad()\n",
    "            # 设置模型为训练模式  Set the model to training mode\n",
    "            model.train()\n",
    "            # 运行模型前向传播    Run model forward propagation\n",
    "            outputs = model(images)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                # 设置模型为评估模式  Set the model to evaluation mode\n",
    "                model.eval()\n",
    "                # 运行模型前向传播  Run model forward propagation\n",
    "                outputs = model(images)\n",
    "\n",
    "        # 计算损失函数   Computed loss function\n",
    "        loss = loss_function(outputs, annotations)\n",
    "        \n",
    "        if training:\n",
    "            # 反向传播计算梯度  Backpropagation computes gradients\n",
    "            loss.backward()\n",
    "            # 根据梯度更新模型参数   Model parameters are updated according to the gradient\n",
    "            optimizer.step()\n",
    "\n",
    "        # 累加损失 Cumulative loss\n",
    "        epoch_loss += loss.item()\n",
    "        # 计算迭代次数  Count the number of iterations\n",
    "        iterations += 1\n",
    "        \n",
    "    return float(epoch_loss/iterations)\n",
    "\n",
    "# 进行训练循环 Training loop\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    # 使用tqdm库创建训练数据集的进度条  \n",
    "    # Training phase\n",
    "    with tqdm(training_loader, unit=\"batch\") as training_epoch:\n",
    "        # 运行一个训练轮次，并返回平均训练损失   Run a training round and return the average training loss\n",
    "        avg_training_loss = run_epoch(training_epoch, \"Training\", training=True)\n",
    "        # 将平均训练损失添加到训练损失列表     Adds the average validation loss to the validation loss list\n",
    "        training_losses.append(avg_training_loss)\n",
    "    \n",
    "    # 使用tqdm库创建验证数据集的进度条\n",
    "    # Validation phase\n",
    "    with tqdm(validation_loader, unit=\"batch\") as validation_epoch:\n",
    "        # 运行一个验证轮次，并返回平均验证损失   Run a training round and return the average training loss\n",
    "        avg_validation_loss = run_epoch(validation_epoch, \"Validation\", training=False)\n",
    "        # 使用学习率调度器根据验证损失调整学习率    Use the learning rate scheduler to adjust the average learning rate based on validation losses\n",
    "        scheduler.step(avg_validation_loss)\n",
    "        # 将平均验证损失添加到验证损失列表    Adds the average validation loss to the validation loss list\n",
    "        validation_losses.append(avg_validation_loss)\n",
    "        \n",
    "        # 如果验证损失达到最低值，保存模型并重置连续没有改善的轮数\n",
    "        # If the validation loss reaches a minimum value, save the model and reset the number of consecutive rounds that have not improved\n",
    "        if avg_validation_loss <= np.min(validation_losses):\n",
    "            epochs_without_improvement = 0\n",
    "            print(\"validation loss decreased to \" + str(avg_validation_loss) + \", saving model\")\n",
    "            model.save_to_path(MODEL_PATH)\n",
    "        # 否则，增加连续没有改善的轮数\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "            # 如果连续没有改善的轮数超过指定的耐心值，停止训练\n",
    "            # If the number of consecutive rounds without improvement exceeds the specified patience value, stop training\n",
    "            if epochs_without_improvement >= EARLY_STOPPING_PATIENCE:\n",
    "                print(\"validation loss of \" + str(np.min(validation_losses)) + \" hasn't improved in last \" + str(EARLY_STOPPING_PATIENCE) + \" epochs, stopping training\")\n",
    "                break\n",
    "    # 绘制损失函数曲线   Plot the training and validation losses after each epoch          \n",
    "    plot_losses()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 使用模型加载保存的权重 Use the model to load the saved weights\n",
    "model.load_from_path(MODEL_PATH)\n",
    "\n",
    "# 创建空列表以保存结果和损失    Create an empty list to store results and losses\n",
    "results = []\n",
    "losses = []\n",
    "\n",
    "# 设置模型为评估模式，禁用梯度计算   Set the model to evaluation mode and disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    # 遍历测试数据集  Iterate over the test data set\n",
    "    for name, image, annotation in testing_loader:\n",
    "        # 将图像数据移至GPU并进行预测  Move the image data to the GPU and make predictions\n",
    "        prediction = model(image.cuda()).clamp(min=-1, max=1)\n",
    "        # 计算损失，并将其转换为浮点数并移至CPU   # Calculate the loss and convert it to a floating point number and move it to the CPU\n",
    "        loss = round(float(loss_function(prediction, annotation.cuda()).cpu()), 4)\n",
    "        # 判断是否通过测试（损失是否小于可接受的测试损失）  Determine if the test is passed (if the loss is less than the acceptable test loss)\n",
    "        passed = loss < ACCEPTABLE_TESTING_LOSS\n",
    "        # 将损失和结果添加到列表中  Add losses and results to the list\n",
    "        losses.append(loss)\n",
    "        results.append(passed)\n",
    "               \n",
    "        # 对图像进行变换，以便可视化  Transform the image for visualization\n",
    "        composed_transforms = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Normalize([-0.485/0.229, -0.456/0.224, -0.406/0.225], [1/0.229, 1/0.224, 1/0.225]),\n",
    "            torchvision.transforms.ToPILImage()\n",
    "        ])\n",
    "        image = composed_transforms(image[0])\n",
    "        image = image.convert(\"RGB\")\n",
    "        # 显示图像  Display image\n",
    "        display(image)\n",
    "        \n",
    "        # 打印图像名称、期望注释、预测注释、损失和测试结果\n",
    "        # Print image names, expected comments, predicted comments, losses, and test results\n",
    "        print(name[0])\n",
    "        print(\"expected: \"+str(annotation.float()[0]))\n",
    "        print(\"predicted: \"+str(prediction.cpu().float()[0]))\n",
    "        print(\"loss: \"+str(loss))\n",
    "        print(\"passed: \"+str(passed))\n",
    "        print(\"\")\n",
    "\n",
    "# 打印测试结果得分和平均损失  Print test results score and average loss\n",
    "print(\"SCORE: \"+str(len([x for x in results if x]))+\"/\"+str(len(results))+\", AVG LOSS: \"+str(round(np.mean(losses), 4)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
